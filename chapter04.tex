\chapter{Implementácia}

\section{Pravdepodobnostná bezkontextová gramatika}
\paragraph{}
Pravdepodobnostná bezkontextová gramatika je bezkontextová gramatika, ktorej pravidlá majú priradenú pravdepodobnosť. Pravdepodobnostná bezkontextová gramatika \(G\) je pätica \(G = (M, T, R, S, P)\), kde:
\begin{itemize}
	\item \(M = { N^i : i = 1,...,n }\) je množina neterminálov
	\item \(T = { w^k : k = 1,...,V }\) je množina terminálov
	\item \(R = { N^i \to \zeta^j : \zeta^j \epsilon (M \cup T)^* }\) je množina pravidiel
	\item \(S = N^1\) je počiatočný neterminál
	\item \(P\) je množina pravdepodobností pravidiel, pre ktoré platí \( \forall i \displaystyle\sum_{i} P(N^i \to \zeta^j) = 1\)
\end{itemize}

\subsection{Tvorba gramatiky}
\paragraph{}
Pri tvorbe gramatiky sme si dali za cieľ zaistiť, aby gramatika spĺňala určité podmienky:
\begin{itemize}
	\item Generovať všetky reťazce zo vstupnej abecedy kratšie ako používateľom zadaná maximálna dĺžka
	\item Vygenerovať každý reťazec práve raz
\end{itemize}

\paragraph{}
V nami vytvorenej gramatike bude kategorizovať slová podľa ich zloženia z jednotlivých typov znakov. Pre každý takýto typ znakov vygenerujeme všetky možné reťazce zložené zo znakov tohto typu. Následne vytvoríme všetky možné predpisy zložené z~kombinácií týchto typov. Uvažujme, že typ 1 obsahuje \(t_1\) znakov a typ 2 obsahuje \(t_2\) znakov a budeme vytvárať reťazce dĺžky 2, kde každý znak patrí do iného typu. Všetkých takýchto reťazcov je \(t_1 * t_2 * 2\). Naša gramatika si bude pamätať len \(t_1 + t_2 + 2\) položiek, z ktorých dokáže spájaním vygenerovať všetkých \(t_1 * t_2 * 2\).

\paragraph{Jednoduché neterminály}
Prvý typ neterminálov, ktoré budeme nazývať jednoduché, obsahujú pravidlá, ktoré majú na pravej strane pravidla iba terminálne symboly. Keďže naša vstupná abeceda obsahuje okolo 70 znakov, medzi ktoré patria veľké a~malé písmena, cifry a niektoré často používané symboly, rozhodli sme sa ich rozdeliť do jednotlivých skupín. Pre každú z týchto skupín sme vytvorili neterminál, ktorý bude reprezentovať sekvenciu pevnej dĺžky zloženú zo znakov danej skupiny. V gramatike tieto neterminály vyjadrujeme pomocou prvého písmena anglického názvu danej skupiny.
\begin{itemize}
	\item U - veľké písmená
	\item L - malé písmená
	\item D - cifry
	\item S - symboly
\end{itemize}
Každý jednoduchý neterminál sa teda skladá z písmena vyjadrujúceho skupinu znakov, ktoré generuje, a čísla popisujúceho dĺžku sekvencie na pravej strane pravidiel tohto neterminálu. Ako napríklad jednoduchý neterminál \(D_1\) vyjadruje pravidlá \(D_1 \to 1 | 2 | ... | 9 | 0 \). Keďže všetkých reťazcov terminálnych znakov dĺžky \emph{k} nad abecedou veľkosti \emph{n} je \( n^k\), rozhodli sme sa zadefinovať maximálnu veľkosť jednoduchého neterminálu, vyjadrujúcu maximálné povolené \(k\). Na základe testov zo sekcií \ref{sec:time} a \ref{sec:pass} sa ako vhodná hodnota ukázalo \(k = 5\). Avšak v prípade generovania malého počtu hesiel sa kvôli optimalizácií času oplatí použiť hodnotu \(k = 4\).

\paragraph{Zložené neterminály}
Jednoduché neterminály nám pomáhajú vyjadrovať sekvenciu znakov práve jedného z vyššie vymenovaných typov. Aby sme boli schopní popísať ľubovolný reťazec tvorený znakmi vstupnej abecedy, budeme tieto jednoduché neterminály skladať do skupín, tieto skupiny budeme nazývať zložené neterminály. Tieto neterminály vyjadrujú vždy jeden možný predpis pre terminálne slovo. Napríklad zložený neterminál \(U_1L_3D_4\) vyjadruje všetky terminálne slová začínajúce na veľké písmeno nasledované tromi malými písmenami, ukončené štvoricou cifier.

\paragraph{}
Kvôli dodržaniu jednoznačnosti generovania nedovoľujeme, aby sa vyskytovali 2 jednoduché neterminály rovnakého typu za sebou. V prípade, že potrebujeme popísať sekvenciu terminálnych znakov jedného typu dlhšiu ako povolené maximum (popísane vyššie), rozdelíme túto sekvenciu do viacerých jednoduchých neterminálov pažravým algoritmom, čiže každý z týchto neterminálov zoberie maximálny možný počet znakov sekvencie. Ak zoberieme heslo pozostávajúce z 9 cifier ako napríklad jedno z najpoužívanejších \emph{123456789} a máme najvyššiu povolenú dĺžku jednoduchého neterminálu nastavenú na 4, toto heslo bude v našej gramatike zapísané ako \(D_4D_4D_1\). Tento spôsob nám zaručí, že nevzniknú dva rôzne zložené neterminály vyjadrujúce ten istý predpis terminálneho slova.

\paragraph{}
Počiatočný neterminál gramatiky \(Z\) bude obsahovať pravidlá prepisujúce tento neterminál na zložené neterminály vyjadrujúce všetky možné predpisy slov kratších ako zadaná maximálna dĺžka.

\subsection{Počítanie pravdepodobností}
\label{sec:Probability}
\paragraph{}
Aby sme vedeli čo najlepšie vyhovieť potrebám používateľa, potrebujeme im prispôsobiť našu gramatiku. Tu začnú zohrávať rolu pravdepodobnosti jednotlivých pravidiel našej gramatiky. Našim cieľom je nastaviť našu gramatiku tak, aby generovala heslá podľa pravdepodobnosti použitia daným používateľom. Úspešnosť tohto učenia gramatiky bude záležať od kvality vstupných dát.
\paragraph{}
Vzhľadom na to, že v dnešnom svete používatelia používajú rôzne služby, ktoré každá odporúča mať jedinečné heslo, používatelia používajú niekoľko hesiel naraz. Tieto heslá by si radi všetky pamätali a preto, ako sme už v úvode spomínali, si často vytvoria pre~seba charakteristický spôsob tvorby a zapamätania si týchto hesiel. V ideálnom prípade by sme chceli aby naše vstupné dáta pozostávali z čo najväčšieho počtu hesiel vytvorených pomocou tohto charakteristického spôsobu, keďže každé upresnenie informácií o~hľadanom hesle nám zvýši rýchlosť nájdenia tohto hesla.
\paragraph{}
Keďže cieľom našej práce je nájsť heslo so 100\% pravdepodobnosťou, čo v najhoršom prípade znamená vygenerovať všetky možné reťazce kratšie ako zadaná maximálna dĺžka hesla, tak základnú gramatiku s pravidlami vieme vygenerovať dopredu a pravidlá tejto gramatiky sa budú meniť len pri zmene maximálnej dĺžky hesla. Preto používanie nášho algoritmu s rôznymi slovníkmi nevyžaduje vyrábanie novej gramatiky až do momentu kedy sa rozhodneme generovať heslá s inou maximálnou dĺžkou. Pravdepodobnosti prepisovacích pravidiel generujúcich terminálne sekvencie budeme rátať ako percento výskytov danej terminálnej sekvencie spomedzi všetkých sekvencií spadajúcich pod tento neterminál. Práve kvôli tomuto spôsobu sme pridali v implementácií možnosť napísať do vstupného slovníku počty výskytov jednotlivých hesiel, aby mal používateľ možnosť zdôrazniť dôležitosť hesla. Vstupné slovníky, ktoré neskôr používame v našich testoch majú formát, kde na každom riadku je heslo s počtom jeho výskytov oddelené medzerou. 

\begin{listing}
\begin{minted}[linenos,
			   tabsize=2]{python}
# ideme po pismenach slova zo slovnika
for i in range(1, len(word)):
	# ak sa zmenil typ znaku na male pismeno
	if (word[i] in lower) and (currentNet != 'L'):
		# k zlozenemu neterminalu pridame jednoduchy posledneho 
		# videneho typu a velkosti
		rule += currentNet + str(i-startI)
		# pripocitame pocet vyskytov retazca daneho posledneho
		# jednoducheho neterminalu
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		# pripocitame pocet vyskytov daneho jednoducheho neterminalu
		ruleCount[currentNet + str(i-startI)] += occ
		# dalsi typ zacina na i-tej pozicii
		startI = i
		# je to retazec malych pismen
		currentNet = 'L'
		# budujeme od zaciatku
		currentSubstring=''
	# ak sa zmenil typ znaku na velke pismeno
	elif (word[i] in upper) and (currentNet != 'U'):
		# k zlozenemu neterminalu pridame jednoduchy posledneho 
		# videneho typu a velkosti
		rule += currentNet + str(i-startI)
		# pripocitame pocet vyskytov retazca daneho posledneho
		# jednoducheho neterminalu
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		# pripocitame pocet vyskytov daneho jednoducheho neterminalu
		ruleCount[currentNet + str(i-startI)] += occ
		# dalsi typ zacina na i-tej pozicii
		startI = i
		# je to retazec velkych pismen
		currentNet = 'U'
		# budujeme od zaciatku
		currentSubstring=''
\end{minted}
\caption{Úprava pravidiel na základe vstupného slova}
\label{lst:grammar1}
\end{listing}
\begin{listing}
\begin{minted}[linenos,
			   tabsize=2]{python}
	# ak sa zmenil typ znaku na cislicu
	elif (word[i] in digit) and (current != 'D'):
		# k zlozenemu neterminalu pridame jednoduchy posledneho
		# videneho typu a velkosti
		rule += currentNet + str(i-startI)
		# pripocitame pocet vyskytov retazca daneho posledneho
		# jednoducheho neterminalu
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		# pripocitame pocet vyskytov daneho jednoducheho neterminalu
		ruleCount[currentNet + str(i-startI)] += occ
		# dalsi typ zacina na i-tej pozicii
		startI = i
		# je to retazec cislic
		currentNet = 'D'
		# budujeme od zaciatku
		currentSubstring=''
	# ak sa zmenil typ znaku na symbol
	elif (word[i] in special) and (current != 'S'):
		# k zlozenemu neterminalu pridame jednoduchy posledneho
		# videneho typu a velkosti
		rule += currentNet + str(i-startI)
		# pripocitame pocet vyskytov retazca daneho posledneho
		# jednoducheho neterminalu
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		# pripocitame pocet vyskytov daneho jednoducheho neterminalu
		ruleCount[currentNet + str(i-startI)] += occ
		# dalsi typ zacina na i-tej pozicii
		startI = i
		# je to retazec symbolov
		currentNet = 'S'
		# budujeme od zaciatku
		currentSubstring=''
	# presiahli sme velkost jednoducheho neterminalu
	elif len(currentSubstring) >= maxNetSize:
		# k zlozenemu neterminalu pridame jednoduchy posledneho
		# videneho typu a velkosti
		rule += currentNet + str(i-startI)
		# pripocitame pocet vyskytov retazca daneho posledneho
		# jednoducheho neterminalu
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		# pripocitame pocet vyskytov jednoducheho daneho neterminalu
		ruleCount[currentNet + str(i-startI)] += occ
		# dalsi typ zacina na i-tej pozicii
		startI = i
		# budujeme od zaciatku
		currentSubstring=''
	currentSubstring += word[i]
...
\end{minted}
\caption{Úprava pravidiel na základe vstupného slova - Pokračovanie}
\label{lst:grammar1-2}
\end{listing}

\paragraph{}
Pri počítaní pravdepodobností zložených neterminálov máme viacero možností ako postupovať.
\paragraph{Priamo zo vstupného slovníka}
Prvý spôsob ako postupovať je identický s tým pre~jednoduché neterminály. Pre každé pravidlo gramatiky prepisujúce počiatočný neterminál na zvolený zložený neterminál vypočítame jeho pravdepodobnosť ako pomer počtu výskytov tohto neterminálu a výskytov všetkých neterminálov dohromady. Existuje taktiež viacero spôsobov ako počítať výskyty zložených neterminálov.
\begin{itemize}
	\item Do výskytov počítame len výskyty hesiel ktoré sú presne reprezentované daným neterminálom
	\item Do výskytov započítame aj výskyty kedy je zvolený neterminál podreťazcom iného neterminálu
\end{itemize}
V oboch týchto variantoch počítame počty výskytov jednoduchých neterminálov. Rozdiel medzi týmito variantami ukážeme na príklade. Majme na vstupe heslo, ktoré je reprezentované zloženým neterminálom \(U_2L_3D_2\), použitím prvého variantu tento zložený neterminál vygeneruje jedno zvýšenie počtu výskytov a to pre tento konkrétny neterminál. Ukážka kódu implementujúceho prvý variant \ref{lst:grammar1}. Druhý variant by na~tomto netermináli vyvolal 2 navýšenia počtu výskytov a to osobitne pre zložené neterminály \(U_2L_3\) a \(U_2L_3D_2\). Aby sme upravili náš program na druhý variant pridali sme pre každú zmenu typu neterminálu pripočítanie výskytov k doteraz vytvorenému zloženému neterminálu, ukážka takto upraveného kódu je v \ref{lst:grammar2}.

\begin{listing}
\begin{minted}[linenos,
			   tabsize=2]{python}
for i in range(1, len(word)):
	if (word[i] in lower) and (currentNet != 'L'):
		rule += currentNet + str(i-startI)
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		ruleCount[currentNet + str(i-startI)] += occ
		# este sme takyto zlozeny neterminal nevideli
		if not rule in rulez['Z']:
			rulez['Z'][rule] = 1
		# pripocitame pocet vyskytov tohto zlozeneho netermialu
		rulez['Z'][rule] += occ
		# pripocitame pocet vyskytov nejakeho neterminalu
		ruleCount['Z'] += occ
		startI = i
		currentNet = 'L'
		currentSubstring=''
	elif (word[i] in upper) and (currentNet != 'U'):
		rule += currentNet + str(i-startI)
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		ruleCount[currentNet + str(i-startI)] += occ
		# este sme takyto zlozeny neterminal nevideli
		if not rule in rulez['Z']:
			rulez['Z'][rule] = 1
		# pripocitame pocet vyskytov tohto zlozeneho netermialu
		rulez['Z'][rule] += occ
		# pripocitame pocet vyskytov nejakeho neterminalu
		ruleCount['Z'] += occ
		startI = i
		currentNet = 'U'
		currentSubstring=''
\end{minted}
\caption{Pripočítanie výskytov k podmnožinám zložených neterminálov}
\label{lst:grammar2}
\end{listing}

\begin{listing}
\begin{minted}[linenos,
			   tabsize=2]{python}
	elif (word[i] in digit) and (current != 'D'):
		rule += currentNet + str(i-startI)
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		ruleCount[currentNet + str(i-startI)] += occ
		# este sme takyto zlozeny neterminal nevideli
		if not rule in rulez['Z']:
			rulez['Z'][rule] = 1
		# pripocitame pocet vyskytov tohto zlozeneho netermialu
		rulez['Z'][rule] += occ
		# pripocitame pocet vyskytov nejakeho neterminalu
		ruleCount['Z'] += occ
		# dalsi typ zacina na i-tej pozicii
		startI = i
		# je to retazec cislic
		currentNet = 'D'
		# budujeme od zaciatku
		currentSubstring=''
	# ak sa zmenil typ znaku na symbol
	elif (word[i] in special) and (current != 'S'):
		# k zlozenemu neterminalu pridame jednoduchy posledneho
		# videneho typu a velkosti
		rule += currentNet + str(i-startI)
		# pripocitame pocet vyskytov retazca daneho posledneho
		# jednoducheho neterminalu
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		# pripocitame pocet vyskytov daneho jednoducheho neterminalu
		ruleCount[currentNet + str(i-startI)] += occ
		# este sme takyto zlozeny neterminal nevideli
		if not rule in rulez['Z']:
			rulez['Z'][rule] = 1
		# pripocitame pocet vyskytov tohto zlozeneho netermialu
		rulez['Z'][rule] += occ
		# pripocitame pocet vyskytov nejakeho neterminalu
		ruleCount['Z'] += occ
		startI = i
		currentNet = 'S'
		currentSubstring=''
\end{minted}
\caption{Pripočítanie výskytov k podmnožinám zložených neterminálov - Pokračovanie}
\label{lst:grammar2-2}
\end{listing}
\begin{listing}
\begin{minted}[linenos,
			   tabsize=2]{python}
	elif len(currentSubstring) >= maxNetSize:
		rule += currentNet + str(i-startI)
		rulez[currentNet + str(i-startI)][str(currentSubstring)] += occ
		ruleCount[currentNet + str(i-startI)] += occ
		# ak uz mame zlozeny neterminal
		if len(rule) > 2:
			# este sme taky nevideli
			if not rule in rulez['Z']:
				rulez['Z'][rule] = 1
			# pripocitame pocet vyskytov tohto zlozeneho netermialu
			rulez['Z'][rule] += occ
			# pripocitame pocet vyskytov nejakeho neterminalu
			ruleCount['Z'] += occ
		startI = i
		currentSubstring=''
	currentSubstring += word[i]
\end{minted}
\caption{Pripočítanie výskytov k podmnožinám zložených neterminálov - Pokračovanie}
\label{lst:grammar2-3}
\end{listing}

\paragraph{Rekurzívne}
Ďalší spôsob spočíva v tom, že zo vstupného slovníka vypočítame pravdepodobnosti len pre jednoduché netermiály. Následne pre zložené neterminály počítame pravdepodobnosti ako súčin pravdepodobností jednoduchých neterminálov, ktoré daný neterminál obsahuje.

\begin{table}[]
\centering
\caption{Ukážka počítania pravdepodobností - gramatika}
\label{gramatikaPP}
\begin{tabular}{ll}
Slovo & Počet výskytov \\ \hline
abc & 20 \\ 
123 & 14 \\ 
113 & 13 \\ 
bbc & 12 \\ 
ab & 8 \\ 
ca & 8 \\ 
c2c & 6 \\ 
bb3 & 5 \\ 
3a3 & 5 \\ 
ca2 & 5 \\ 
a & 2 \\ 
b & 2 \\ 
2 & 2 \\ 
31 & 1 \\ 
122 & 1
\end{tabular}
\quad
\begin{tabular}{l|lll}
Pravidlo & \(p_{zakladna}\) & \(p_{podretazce}\) & \(p_{rekurzivne}\) \\ \hline
\(L1 \to c\) & 0,8035 & 0,8035 & 0,8035 \\
\(L1 \to a\) & 0,1428 & 0,1428 & 0,1428 \\
\(L1 \to b\) & 0,0535 & 0,0535 & 0,0535 \\
\(L2 \to ab\) & 0,4328 & 0,4328 & 0,4328 \\
\(L2 \to bb\) & 0,2686 & 0,2686 & 0,2686 \\
\(L2 \to ca\) & 0,2089 & 0,2089 & 0,2089 \\
\(L2 \to aa|ac|ba|bc|cb|cc\) & 0,0149 & 0,0149 & 0,0149 \\
\(D1 \to 3\) & 0,7288 & 0,7288 & 0,7288 \\
\(D1 \to 2\) & 0,2542 & 0,2542 & 0,2542 \\
\(D1 \to 1\) & 0,0169 & 0,0169 & 0,0169 \\
\(D2 \to 12\) & 0,4210 & 0,4210 & 0,4210 \\
\(D2 \to 11\) & 0,3680 & 0,3680 & 0,3680 \\
\(D2 \to 13|21|22|23|31|32|33\) & 0,0263 & 0,0263 & 0,0263 
\end{tabular}
\begin{tabular}{l|lll}
Pravidlo & \(p_{zakladna}\) & \(p_{podretazce}\) & \(p_{rekurzivne}\) \\ \hline
\(Z \to L2L1\) & 0,2796 & 0,2558 & 0,0061 \\
\(Z \to D2D1\) & 0,2457 & 0,2248 & 0,0004 \\
\(Z \to L2\) & 0,1440 & 0,1317 & 0,1440 \\
\(Z \to L2D1\) & 0,0932 & 0,0852 & 0,0036 \\
\(Z \to L1D1L1\) & 0,0593 & 0,0542 & 0,00004 \\
\(Z \to D1L1D1\) & 0,0508 & 0,0465 & 0,00002 \\
\(Z \to L1\) & 0,0423 & 0,0387 & 0,0423 \\
\(Z \to D1\) & 0,0254 & 0,0232 & 0,0254 \\
\(Z \to D2\) & 0,0169 & 0,0155 & 0,0169 \\
\(Z \to L1D1\) & 0,0084 & 0,0542 & 0,0010 \\
\(Z \to L1D2\) & 0,0084 & 0,0077 & 0,0007 \\
\(Z \to D2L1\) & 0,0084 & 0,0077 & 0,0007 \\
\(Z \to D1L1\) & 0,0084 & 0,0465 & 0,0010 \\
\(Z \to D1L2\) & 0,0084 & 0,0077 & 0,0036 \\
\end{tabular}
\end{table}

\subsection{Generovanie hesiel}
\paragraph{}
\label{fig:stromyOdvodenia}
\Tree [.Z(0) [.L2(0) \textit{ab} ]
           [.L1(0) \textit{c} ]]
\Tree [.Z(1) [.D2(0) \textit{12} ]
           [.D1(0) \textit{3} ]]
\Tree [.Z(1) [.D2(1) \textit{11} ]
           [.D1(0) \textit{3} ]]
\Tree [.Z(0) [.L2(1) \textit{bb} ]
           [.L1(0) \textit{c} ]]

\paragraph{}
Dôležitým aspektom používania bezkontextových gramatík je práve spôsob generovania hesiel. Našim hlavným cieľom bolo generovanie hesiel pomocou gramatiky od~najpravdepodobnejšieho z nich. Aby sme toto vedeli robiť čo najefektívnejšie, ako prvé sme si usporiadali pravidlá jednotlivých neterminálov vzostupne podľa pravdepodobnosti. Na diagramoch na začiatku sekcie \ref{fig:stromyOdvodenia} vidíme stromy odvodenia pre 4 najpravdepodobnejšie slová gramatiky popísanej v tabuľke \ref{gramatikaPP}. Čísla v zátvorkách určujú index použitého pravidla pre daný neterminál. Výpisom týchto hodnôt do poľa v preorder poradí dostaneme vektor určujúci odvodenia daného terminálneho slova. Napríklad na~základe diagramov na začiatku sekcie \ref{fig:stromyOdvodenia} slovu \emph{bbc} prislúcha vektor \((0,1,0)\).

\paragraph{}
\begin{listing}
\begin{minted}[linenos,
			   tabsize=2]{python}
pocet = 0
fronta.push(pravdepodobnost([0,0,0]), (0, [0,0,0]))
while fronta is not empty:
	# prvok je dvojica (rad vektora, vektor)
	aktualnyPrvok = fronta.pop()
	vypisTerminalneSlovo(aktualnyPrvok[1])
	pocet += 1
	if pocet > pozadovanyPocetHesiel:
		break
	if aktualnyPrvok[0] == 0:
		# index aktualne pouziteho pravidla pre neterminal 'Z'
		tmp = aktualnyPrvok[1][0]
		novyVektor = [tmp + 1] + [0] * velkost(Neterminal['Z'][tmp])
		novyPrvok = (novyVektor, 0)
		fronta.push(pravdepodobnost(novyVektor), novyPrvok)
		aktualnyPrvok[0] += 1

	for x in (aktualnyPrvok[0], velkost(aktualnyPrvok[1])):
		novyVektor = aktualnyPrvok[1]
		novyVektor[x] += 1
		novyPrvok = (novyVektor, x)
		fronta.push(pravdepodobnost(novyVektor), novyPrvok)
\end{minted}
\caption{Pseudokód generovania hesiel}
\label{lst:pseudoGenerovanie}
\end{listing}

\paragraph{}
V \ref{lst:pseudoGenerovanie} vidíme pseudokód pre algoritmus generujúci heslá z gramatiky. Algoritmus začína pridaním dvojice rád vektora a vektor do prioritnej fronty. Táto fronta zoraďuje prvky na základe ich pravdepodobnosti. Následne algoritmus vojde do cyklu, z ktorého vyjde len ak vygeneruje požadovaný počet hesiel alebo vyprázdni celú frontu, čo sa stane v prípade, že by vygeneroval všetky možné heslá pre danú gramatiku.

\paragraph{}
Ako je vidieť na diagramoch na začiatku sekcie \ref{fig:stromyOdvodenia}, stromy odvodenia pre heslá s rovnakým predpisom majú takú istú štruktúru. Pri zmene použitého pravidla pre počiatočný neterminál musíme ošetriť potenciálnu zmenu štruktúry stromu odvodenia (riadky 11 až 14). Následne algoritmus prejde všetky susedné vektory práve spracovaného vektoru a pridá ich do fronty s aktualizovaným rádom a pravdepodobnosťou (riadky 16 až 20).

\paragraph{}
Dôležitým prvkom tohto algoritmu je rád vektora, bez ktorého by sme generovali veľké množstvo rovnakých vektorov, ktoré by sme dostali úpravou hodnôt vektora v~inom poradí. Napríklad ak by sme zvýšili najprv index na pozícii 1 a následne 3, dostali by sme to isté, ako keby sme zvýšili na pozícii 3 a potom 1. Rád vektoru je číslo určujúce pozíciu najvyššieho zmeneného indexu. Pri generovaní susedných vektorov dovolíme meniť indexy len na pozíciach vyšších alebo rovných ako je aktuálny rád vektora. Týmto zaručíme zmenu použitých pravidiel v preorder poradí vzhľadom na strom odvodenia.

\begin{table}[]
\centering
\caption{Ukážka krokov algoritmu pre neterminál \(U_1L_3D_2\)}
\label{postupAlgoritmu}
\begin{tabular}{l|lll}
Ľavá strana & Pravá strana & p & i \\ \hline
\(U_1\) & A & 0,7 & 0 \\
\(U_1\) & B & 0,2 & 1 \\
\(U_1\) & C & 0,1 & 2 \\
\(L_4\) & minf & 0,6 & 0 \\
\(L_4\) & fmfi & 0,3 & 1 \\
\(L_4\) & dipl & 0,1 & 2 \\
\(D_2\) & 47 & 0,8 & 0 \\
\(D_2\) & 42 & 0,2 & 1 \\
\end{tabular}
\quad
\begin{tabular}{lll}
p & (rád, vektor) & slovo \\ \hline
0.336 & (0, [0, 0, 0]) & Aminf47 \\ \hline \hline
0.168 & (1, [0, 1, 0]) & Afmfi47 \\
0.096 & (0, [1, 0, 0]) & Bminf47 \\
0.084 & (2, [0, 0, 1]) & Aminf42 \\ \hline \hline
0.096 & (0, [1, 0, 0]) & Bminf47 \\
0.084 & (2, [0, 0, 1]) & Aminf42 \\
0.056 & (1, [0, 2, 0]) & Adipl47 \\
0.042 & (2, [0, 1, 1]) & Afmfi42
\end{tabular}
\end{table}

\paragraph{}
V tabuľke \ref{postupAlgoritmu} demonštrujeme dva kroky nášho algoritmu na generovanie hesiel. V tomto príklade sa sústredíme na generovanie rôznych terminálnych slov zo zloženého neterminálu \(U_1L_3D_2\). V ľavej časti tabuľky môžme vidieť zadefinované prepisovacie pravidlá pre tento neterminál aj s pravdepodobnosťami, ktoré majú priradené. V pravej časti simulujeme obsah našej prioritnej fronty, kde dvojitou vodorovnou čiarou sú oddelené stavy tejto fronty v rôznych krokoch algoritmu. V počiatočnom stave máme vo fronte prvý prvok ukazujúci na najpravdepodobnejšie heslo generované z definovaných pravidiel. Algoritmus tento prvok vyberie z fronty a následne tam vloží prvky označujúce heslá vzdialené práve na jednu zmenu použitého pravidla. Tieto novo pridané prvky sú automaticky zoradené podľa pravdepodobností vďaka tomu, že na pozadí je naša fronta reprezentovaná prioritnou haldou. 

\paragraph{}
V druhom kroku algoritmu vyberie prvok z najvyššou pravdepodobnosťou. Opäť do fronty pridáme prvky vyjadrujúce heslá vzdialené na jednu zmenu použitého pravidla. Tu si treba všimnúť, že sme nepridali prvok s vektorom [1, 1, 0], keďže rád práve spracovaného prvku je 1, čiže môžme meniť len indexy 1 a 2, ktoré sú väčšie alebo rovné ako rád vektora. Týmto spôsobom algoritmus pokračuje až pokiaľ sa nevygeneruje požadovaný počet hesiel alebo sa nevyprázdni fronta. Fronta sa môže vyprázdniť len ak prejdeme cez všetky možné heslá, keďže jediný moment kedy nepribudne žiaden prvok do fronty je ak rád vektora bude rovný jeho dĺžke a v poslednom jednoduchom netermináli sme použili už všetky jeho pravidlá.

\paragraph{}
V zdrojovom kóde \ref{lst:generujSusedov} môžme vidieť časť kódu zodpovednú za napĺňanie prioritnej fronty ďalšími kandidátmi na najbližšie vygenerované heslo. Premenná \(task\) je usporiadaná dvojica (rád, vektor). Algoritmus prejde od člena určeného rádom vektora až po koniec vektora (riadok 1) a pre každý prvok posunie index ukazujúci na aktuálne použitý prvok (riadok 4). Taktiež vypočíta pravdepodobnosť hesla reprezentovaného novým stavom vektora (riadok 3 a 7). Túto pravdepodobnosť spolu s usporiadanou dvojicou obsahujúcou zmenený rád vektora a samotný vektor vloží do prioritnej fronty (riadok 8 a 9).

\begin{listing}
\begin{minted}[linenos,
			   tabsize=2]{python}
for x in range(task[0],len(task[1])):
	tmp = copy.deepcopy(task[1])
	newpriority = priority / rulez[net[(x-1)*2:x*2]][tmp[x]][1]
	tmp[x] += 1
	if tmp[x] >= len(rulez[net[(x-1)*2:x*2]]):
		continue
	newpriority = newpriority * rulez[net[(x-1)*2:x*2]][tmp[x]][1]
	newtask = (x, tmp)
	add_task(newtask, newpriority)
\end{minted}
\caption{Generovanie všetkých susedných vektorov}
\label{lst:generujSusedov}
\end{listing}

\paragraph{}
Veľký nedostatok použitia bezkontextových gramatík je veľkosť pamäte, ktorá je potrebná na samotný zápis gramatiky na disku. V tvare JSON mal pri gramatike generujúcej 12 znakové heslá približne 1 gigabajt. Väčší problém nastáva s pamäťou použitou pri samotnom behu algoritmu. Počas testov na zistenie vplyvu jednotlivých parametrov na veľkosť potrebnej pamäte sme zistili, že najväčšia časť použitej pamäte je potrebná na uloženie našej gramatiky v asociatívnom poli.

\paragraph{}
Poslednou vecou čo sme riešili v implementácií bezkontextových gramatík bola možnosť prerušovaného generovania. Vtedy má používateľ možnosť generovať požadované heslá po ľubovoľne veľkých častiach.

\paragraph{}
Pri ukončení generovania bez ohľadu na dôvod, splnenie počtu vygenerovaných hesiel alebo prerušenie od používateľa, zapíšeme do súboru aktuálny stav generovania. Tento stav zahŕňa:
\begin{itemize}
	\item Cesta ku gramatike, ktorá bola použitá na generovanie
	\item Aktuálny zoznam prvkov prioritnej fronty
\end{itemize}
Vďaka týmto dvom informáciam dokáže náš algoritmus následne pokračovať v generovaní slov od posledného vygenerovaného.

\section{Markovovský zdroj}
\label{sec:Markov}
\paragraph{}
Po implementácií vyššie uvedeného algoritmu na generovanie hesiel pomocou pravdepodobnostných bezkontextových gramatík a odhalení nedostatkov čo sa týka pamäťovej náročnosti, sme sa rozhodli implementovať ešte jednu metódu. Tou je Markovovský zdroj. Ako sme písali v predošlej kapitole, jedná sa o náhodný proces, pre ktorý platí, že nasledujúce vygenerované písmeno záleží len od posledného stavu a nie od postupnosti stavov, ktoré mu predchádzali. Markovovské zdroje sa veľmi často používajú práve pri generovaní prirodzeného jazyka. Práve preto boli vhodným kandidátom pre generovanie hesiel na základe znalostí získaných zo vstupného slovníka. 

\paragraph{}
Bohužiaľ táto metóda nespĺňa ani jednu z podmienok, ktoré sme si dali za cieľ pri bezkontextových gramatikách:
\begin{itemize}
	\item Generovať všetky reťazce zo vstupnej abecedy kratšie ako používateľom zadaná maximálna dĺžka
	\begin{itemize}
		\item Pravdepodobnosti jednotlivých znakov sú inicializované na 0, Markovovský zdroj ich nikdy nevygeneruje
	\end{itemize}
	\item Vygenerovať každý reťazec práve raz
	\begin{itemize}
		\item Keďže tomuto zdroju nič nebráni v tom vygenerovať viac krát počas behu to isté slovo
	\end{itemize}
\end{itemize}

\paragraph{}
Aj keď druhú podmienku nevedia Markovovské zdroje splniť už priamo z definície, s prvou sme sa pokúsili niečo vymyslieť. Najprv sme sa pokúšali inicializovať pravdepodobnosti všetkých znakov na nenulovú hodnotu. Toto však spôsobilo, že sa zdroj relatívne ľahko dostal medzi prefixy, ktoré neboli definované. Pri takýchto prefixoch majú všetky znaky rovnakú pravdepodobnosť. Dôsledkom tohto nastávalo cyklenie sa v týchto neznámych stavoch, čo spôsobovalo generovanie dlhých nezmyselných reťazcov znakov. Preto sme sa snažili nájsť spôsob ako nastaviť pravdepodobnosti nevidených stavov na nenulové, avšak dostatočne malé aby sa v nich samotný algoritmus necyklil.

\paragraph{}
Pri takto definovanom Markovovskom zdroji dokážeme všetky stavy tohto zdroja rozdeliť do dvoch množín prefixov. Videné prefixy sú také, ktoré aspoň raz nastali pri učení podľa vstupného slovníka. Takéto stavy majú pre aspoň jeden znak slovníka nenulovú pravdepodobnosť. Druhou väčšou skupinou prefixov sú nevidené prefixy, ktoré sa nevyskytli nikde vo vstupnom slovníku a preto pre všetky znaky našej abecedy je pravdepodobnosť prechodu nulová. Keďže chceme upraviť náš Markovovský zdroj tak, aby mal možnosť generovať všetky možné heslá, potrebujeme tieto nulové pravdepodobnosti zmeniť na nenulové. 

\begin{table}[]
\centering
\caption{Ukážka Markovovského zdroja - prefix dĺžky 2}
\label{tbl:MarkovZdroj}
\begin{tabular}{ll}
Slovník & Výskyty\\ \hline
abc & 3 \\
12 & 2 \\
b1c & 2 \\
bb1 & 2
\end{tabular}
\quad
\begin{tabular}{l|llllll}
	& a & b & c & 1 & 2 & \textbackslash{}n \\ \hline
ab 	& -	& - & 3 & - & - & - \\
bc 	& - & - & - & - & - & 3 \\
c\textbackslash{}n & - & 1 & - & 2 & - & - \\
\textbackslash{}n1 & - & - & - & - & 2 & - \\
12 & - & - & - & - & - & 2 \\
2\textbackslash{}n & - & 2 & - & - & - & - \\
\textbackslash{}nb & - & - & - & 2 & - & - \\
b1 & - & - & 2 & - & - & 1\\
1c & - & - & - & - & - & 2 \\
bb & - & - & - & 1 & - & -
\end{tabular}
\end{table}

\paragraph{}
Videné stavy nemusia mať určené pravdepodobnosti pre všetky znaky nášho vstupného slovníka. Pre tieto znaky nastavíme pravdepodobnosti, ktoré v pôvodnom algoritme majú nulovú pravdepodobnosť, na hodnotu \(\varepsilon > 0\). Táto hodnota by mala vyjadrovať pravdepodobnosť prechodu zo stavu v ktorom je prefix známy (z dát vo vstupnom súbore) do stavu kedy je prefix neznámy a pravdepodobnosti všetkých znakov sú nulové. Domnievame sa, že pre správne fungovanie algoritmu by hodnota \(\varepsilon\) mala byť niekoľkonásobne menšia ako najnižšia známa pravdepodobnosť pre daný prefix. Vplyv tejto konštanty na výkon Markovovského zdroja je znázornený na grafe \ref{fig:MarkovV2}.

\paragraph{}
Po prechode nášho algoritmu do stavu, ktorý nebol videný počas inicializácie programu potrebujeme nastaviť pravdepodobnosti všetkých znakov našej abecedy. Pravdepodobnosť jednotlivých znakov nastavíme na hodnotu \(\varepsilon\) ak sa jedná o znak pomocou ktorého v ďalšom kroku algoritmu vznikne videný prefix. V prípade, že znak dostane náš algoritmus do stavu s iným neznámym prefixom, nastavíme tomuto znaku pravdepodobnosť \(\delta\), ktorá je niekoľkokrát menšia ako \(\varepsilon\). Opäť vplyv tejto konštanty na výsledky algoritmu je znázornený na grafe \ref{fig:MarkovV2}. Použitím hodnôt \(\varepsilon\) a \(\delta\) by sme mali dostať algoritmus používajúci Markovovský zdroj do stavu, kedy v konečnom čase dokáže vygenerovať ľubovolný počet hesiel.

\paragraph{}
Jediná informácia, ktorú si algoritmus používajúci Markovovský zdroj pamätá, je tabuľka pravdepodobností nasledovania znakov po danom prefixe. V pôvodnej implementácií tohto algoritmu sme si zoznam prefixov pamätali ako kľúče v asociatívnom poli. Hodnoty týchto kľúčov boli zoznamy pravdepodobností o veľkosti vstupnej abecedy. Index pravdepodobnosti zodpovedal indexu znaku v zápise vstupnej abecedy, ktorému táto pravdepodobnosť prislúcha.

\paragraph{}
Pri implementácií upraveného Markovovského zdroja sme spravili optimalizáciu, pri ktorej si informáciu o pravdepodobnostiach pamätáme len pre znaky a prefixy, ktoré sa vyskytujú vo vstupnom slovníku, ktorý dostal na vstupe. Týmto nám vznikne riedka matica, ktorú si v programe pamätáme pomocou asociatívneho poľa. Toto asociatívne pole obsahuje kľúče pre znaky ku ktorým vieme priradiť pravdepodobnosť na základe vstupného slovníka. Taktiež sme si definovali množinu videných stavov, ktorá bola implementovaná pomocou pythonovského typu \emph{set}. Toto avšak neprinieslo očakávane zrýchlenie a overovanie, či sme stav videli vo vstupnom slovníku priamo v asociatívnom poli s pravdepodobnosťami.

\paragraph{}
V prípade, že sa algoritmus dostane do stavu, kedy sa aktuálny prefix nenachádzal vo vstupnom slovníku, prejde cez všetky znaky vstupnej abecedy a každému priradí pravdepodobnosť \(\varepsilon\) ak sa vygenerovaním tohto znaku dostane do známeho prefixu alebo pravdepodobnosť \(\delta\) ak pridanie tohto znaku vedie do ďalšie stavu s neznámym prefixom. Rozdiely v čase a potrebnej pamäti na vygenerovanie pevne daného počtu hesiel medzi pôvodnou implementáciou a našou optimalizáciou je ukázaný v grafe \ref{fig:memOptimization}.

\paragraph{}
Rozdiely vo veľkosti \(\varepsilon\) oproti najmenšej nenulovej pravdepodobnosti pre ten prefix a \(\delta\) od \(\varepsilon\) by mali zaručiť, že algoritmus sa snaží preferovať heslá, ktoré sa skladajú z~kombinácií znakov videných na vstupe. Výsledky tohto algoritmu pre rôzne nastavené hodnoty koeficientov \(\varepsilon\) a \(\delta\) sú znázornené v kapitole Evaluácia výsledkov.

\paragraph{}
V tomto prípade sme zvažovali aj použitie možnosti zmeny týchto pravdepodobností počas behu programu podobne ako pri simulovanom žíhaní. Zo začiatku by sme tieto pravdepodobnosti nastavili na relatívne nízke hodnoty a s počtom hesiel vygenerovaných našim algoritmom by sa tieto hodnoty zväčšovali aby mal algoritmus vyššiu tendenciu dostať sa aj k menej pravdepodobným heslám. Bohužiaľ z dôvodu časovej tiesne sme nenašli priestor na implementáciu a preskúmanie takto upraveného algoritmu.